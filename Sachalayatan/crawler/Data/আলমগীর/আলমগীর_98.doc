বাংলা বানান শোধক (দ্বিতীয় ও শেষ কিস্তি)



আগের লেখায় যুক্তি দিয়েছিলাম যে ইংরেজী বা অন্যান্য ভাষার মতো বাংলাতে নিয়ম-ভিত্তিক স্পেলচেকার বানানো প্রায় অসম্ভব। একমাত্র গ্রহণযোগ্য বিকল্প হলো সম্ভাব্য সব শব্দের তালিকা তৈরি করে তার ভিত্তিতে স্পেল চেকার বানানো।
শব্দ তালিকা:
সম্ভাব্য সব শব্দের তালিকা বানানো খুব কঠিন একটা কাজ। অভিধানে সাধারণত শব্দের মূল ভুক্তি থাকে; সে শব্দ থেকে আর নতুন যেসব শব্দ হতে পারে তার বিস্তারিত কোন তালিকা থাকে না। তবে প্রায় সময়ই, প্রয়োগ দেখিয়ে একাধিক উদাহরণ থাকে। এসব প্রয়োগ থেকে একটি exhaustive তালিকা হয়ত বানানো সম্ভব। কিন্তু এটা অনেক পরিশ্রমের কাজ হবে। পরিশ্রমটা শব্দ টাইপ করতে না, সেগুলো ঠিকমতো টাইপ করা হয়েছে কি না তা যাচাই করতে। অভিধান থেকে নেয়া শব্দতালিকাতে শব্দগুলো আভিধানিক ক্রমে থাকবে। এ ক্রমে থাকার দরুণ তা যাচাই করা কঠিন। আমাদের মস্তিষ্ক বাংলা শব্দ এরকম তালিকা আকারে দেখে অভ্যস্ত নয়, তাই অল্প কিছু শব্দ দেখার পরই মাথা আউলিয়ে যায়। মাথা সুস্থির রেখে এ কাজ করতে গেলে সুদীর্ঘ সময়ের প্রয়োজন।
এর বিকল্প হিসেবে আমরা ভিন্ন উপায়ে শব্দতালিকা বানাতে পারি। সেটা হচ্ছে বানান ভুল নেই এমন প্রচুর লেখা থেকে শব্দ ছেঁকে নিয়ে। যেমন, প্রথম আলোর গত এক বৎসরের লেখাগুলো থেকে আমরা প্রোগ্রাম চালিয়ে ব্যবহৃত সব শব্দের একটা ভাল তালিকা পেতে পারি। এ ধরনের তালিকাতে মানুষ, স্থান ইত্যাদি নাম-বিশেষ্য থাকবে- সেটা আমাদের জন্য সুবিধা। আবার এ তালিকাতে ভুল শব্দ থাকতে পারে সেটাও যাচাই করতে হবে। তার চেয়ে বড় কথা, প্রথম আলো মূলত সংবাদ প্রকাশ করে বলে সম্ভবত বিশেষ কিছু শব্দের প্রতি দুর্বলতা আছে সেখানে। সে ক্ষেত্রে পরিসংখ্যানটা আনবায়সড হবে না। এ বায়াস দূর করতে হলে কোন প্রকাশনা সংস্থা থেকে প্রচুর লেখা জোগাড় করার দরকার হবে। উল্লেখ্য, আমি এখনও বাংলা প্রমিত লেখার উল্লেখযোগ্য কোন সংগ্রহ বা করপাস পাইনি। ইংল্যান্ডের একটা বিশ্ববিদ্যালয়ের কিছু সংগ্রহ আছে, তবে তাতে কনভার্শনগত প্রচুর ভুল আছে। আর লেখাগুলোও বিদ্যাসাগর আমলের।
প্রথম আলো থেকে শব্দ সংগ্রহের কাজটা তুলনামূলকভাবে সহজ। প্রথম আলোর কাছে চাইতে পারি, সাড়া না পেলে অনলাইনে থাকা তাদের আর্কাইভকে স্ক্র্যাপ করে প্রয়োজনীয় ডেটা সংগ্রহ করতে পারি। কোন প্রকাশনা সংস্থা তাদের লেখা শেয়ার করতে রাজী হবে না, এটা মনে হয় ধরেই নিতে পারি।
প্রযুক্তিগত সীমাবদ্ধতা:
আমার হিসাবে একটা নির্ভরযোগ্য বানান শোধক বানাতে হলে শব্দ তালিকায় আনুমানিক সাড়ে তিন থেকে চার লাখ শব্দ থাকবে। বাংলা ভাষায় শব্দের গড় দৈর্ঘ্য প্রায় ৭/৮ অক্ষরের মতো। ইউনিকোডের utf-8 নিয়মে বাংলা প্রতিটি মূল অক্ষরের জন্য তিন বাইট জায়গা লাগে। সংযুক্ত বর্ণের বেলায় সংযোগকারী বর্ণগুলোকে আলাদা বর্ণ ধরে হিসাব করতে হবে। বাংলা শব্দে গড়ে কী পরিমাণ সংযুক্ত বর্ণ থাকে তার পরিসংখ্যান আমার অজানা। আনুমানিক হিসাবে ধরে নিই গড়ে প্রতি  শব্দে ১০টি বর্ণ থাকে (সংযুক্ত বর্ণ খুব কমই ব্যবহৃত হয়)। তার মানে, প্রতিটি শব্দের জন্য আমাদের ১০×৩ = ৩০ বাইট মেমরির দরকার। শব্দের শেষ চিহ্ণ ও আরো কিছু ওভারহেড মিলিয়ে সেটা ৩৫ ধরে নেয়া যাক। প্রতিটি শব্দের জন্য ৩৫ হিসাবে ৩.৫ লাখ শব্দের জন্য মেমরির প্রয়োজন প্রায় ১২ মেগার।
বানান পরীক্ষার সময় শব্দতালিকাতে আমাদের অহরহ খুঁজতে হবে। তাই শব্দগুলোকে এমনভাবে রাখতে হবে যাতে খুব দ্রুত তাতে খোঁজ করা যায়। এ কাজের জন্য সবচেয়ে উপযুক্ত ডেটা স্ট্রাকচার হলো হ্যাশম্যাপ। ফাইলে রাখা শব্দের তালিকা থেকে হ্যাশম্যাপ বানাতে বেশ অনেকটা সময় লেগে যাবে। কিন্তু, একবার বানানো হয়ে গেলে তাতে শব্দ খুঁজে পেতে তেমন একটা সময় লাগবে না।
বানান পরীক্ষার জন্য আমরা প্রদত্ত শব্দকে শব্দতালিকাতে খুঁজে দেখব। তালিকাতে থাকলে শব্দটি সঠিক, আর না থাকলে তার ভুল বলে ধরে নেব।
সাজেশন/পরামর্শ তৈরী:
এটি হচ্ছে স্পেল চেকারের সবচেয়ে কঠিন অংশ। নির্ভরযোগ্য সাজেশন দিতে পারার উপরই  একটা স্পেল চেকারের ভাল-মন্দ নির্ভর করে। সাজেশনের জন্য আলাদা তালিকা রাখা যেতে পারে, আবার মূল তালিকার সাথেও থাকতে পারে। যে ভাবেই রাখা হোক, সাজেশন করার জন্য শব্দের পরিবর্তে তার মেটাকোড রাখতে হবে যাতে সাজেশন বের করার সময় কাছাকাছি শব্দের হদিস পাওয়া যায়। এবার পাওয়া শব্দগুলোকে তাদের মেরিট অনুসারে সাজাতে হবে যাতে সবচেয়ে বেশী সম্ভাবনার শব্দটি সাজেশন তালিকার প্রথমে আসে। ঠিক কী পদ্ধতিতে শব্দের মেরিট ঠিক করা হবে তা নিয়ে অনেক চিন্তার অবকাশ আছে।
সাজেশন বা পরামর্শ তৈরীর সময় একজন সাধারণ লেখক বাংলা লেখার সময় কী ধরনের ভুল করে তা জানা থাকলে অনেক সুবিধা হবে। বাংলা লেখার সময় কী ধরনের ভুল বেশী হয় তার সঠিক পরিসংখ্যান নেই। এখন অনেকে ইংরেজী উচ্চারণে বাংলা লিখছে (যেটাকে ফনেটিক বলছে অনেকে)। তাদের বেলায় ভুলের ব্যপারটা ভিন্ন হবে এটা আমি নিশ্চিত। বিজয় দিয়ে লিখে যারা কনভার্ট করে, বা ইউনিবিজয় দিয়ে লিখে তাদের ভুলের পরিসংখ্যানটা কিছুটা অনুমেয়। তবে এক্ষত্রেও গবেষণার সুযোগ আছে। 
(এ ব্যপারটা নিয়ে আমি সচলের কিছু লেখকের লেখার উপর একটা কাজ করার ইচ্ছা রাখি। তাদের বেশ কিছু লেখা সংগ্রহ করে তাতে ভুলের পরিসংখ্যান বের করতে চেষ্টা করব। পরে, তারা কে কী পদ্ধতিতে টাইপ করেছেন তা জানতে চাইব। কার কার লেখা বাছাই করব তা এখনই বলছি না, তাতে পরিসংখ্যান সঠিক হবে না। আর এর ফলাফল স্পেলচেকার ছাড়াও অন্য কাজে লাগবে। এতে কপিরাইটের সমস্যা আছে বলে মনে করছি না।  )
অনলাইন বনাম ডেস্কটপ:
ইন্টারনেটের গতি বাড়তে থাকায় অনেকেই অনলাইন টুল পছন্দ করে। সেজন্য অনলাইন স্পেলচেকার যে জনপ্রিয় হবে এতে কোন সন্দেহ নেই। কিন্তু এক্ষেত্রে কিছু সীমাবদ্ধতা আছে।
প্রথম দিকে যেমন বলেছি, যে কেবল শব্দতালিকার আকার হতে পারে ১২মেগ। সেটা হ্যাশম্যাপে রাখলে তা অন্তত ২০/৩০ মেগ মেমরি নিবে। পিএইচপি কোন স্ক্রিপ্টের  জন্য এটা অস্বাভাবিক। আবার এই ১২মেগা ডিস্ক থেকে প্রতিবার পড়ার জন্য সার্ভারের স্পিডের উপর নির্ভর করে ১/২ মিনিট পর্যন্ত লেগে যেতে পারে। দ্বিতীয়ত, সাজেশন তৈরি কালে সবচেয়ে বেশী সময় ব্যয়িত হয়। সার্ভারের সীমাবদ্ধতার জন্য  পিএইচপি কোন স্ক্রিপ্ট অধিক সময় ধরে চলতে পারবে না।
এ দুটো সমস্যা এড়ানোর একমাত্র উপায় হলো ডেডিকেটেড সাভার্র ব্যবহার করা। এতে করেও পিইএচপি কাজটা করতে পারবে কিনা সন্দেহ। সি++ এ লিখে একটা সার্ভিস ডেমন হিসাবে চালালে তা অনেক দ্রুত হবে, এটা অনুমান করতে পারি। 
অন্যান্য কথা:
স্পেলচেকার বানাতে প্রযুক্তিগত যে সমস্যা তা কাটানো তত কঠিন না যতটা কঠিন একটা শব্দ তালিকা জোগাড় করা। সাধারণ ভুলের একটা পরিসংখ্যান দাঁড়া করানোও  কঠিন হবে না। শব্দ তালিকা একা কারো পক্ষে বানানো বছর খানেকের কাজ। একাজে দলগত অংশগ্রহণ অপরিহার্য।

আমি স্পেলচেকারের উপর দুটো লেখা লিখার সাহস করেছি একটা মাত্র কারণে। সেটা হচ্ছে নিজে সেটা বানানোর জন্য ছ'মাসের মতো সময় ব্যয় এবং কিছু একটা দাঁড় করাতে পারার জন্য। আমি যা বানিয়েছি তা কেবল নিজের কম্পউটারে চলে। এতে ব্যবহৃত শব্দতালিকা অঙ্কুর প্রণীত পাবলিক তালিকা। তালিকাটি ততটা ভাল না, অদ্ভুত শব্দও প্রচুর, তাই স্পেল চেকারের আচরণও অনেকটা তেমনি। এটি পাওয়া যাবে এখানে। অনলাইনে চলতে হলে সে সফটওয়ারটার একটা ডেডিকেটেট সার্ভারের দরকার হবে। 


 
